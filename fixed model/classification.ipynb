{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/lab606a/.virtualenvs/keras/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/lab606a/.virtualenvs/keras/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/lab606a/.virtualenvs/keras/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/lab606a/.virtualenvs/keras/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/lab606a/.virtualenvs/keras/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/lab606a/.virtualenvs/keras/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "## import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, CuDNNLSTM, Activation, Bidirectional\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set GPU memory\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104000, 91)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasetset = pd.read_csv(\"./datasets/split by random for distributed/classification/increasing_fixed_dataset.csv\", header=None)\n",
    "datasetset = datasetset.fillna(0)\n",
    "datasetset = np.array(datasetset)\n",
    "datasetset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104000, 90)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = datasetset[:,1:]\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = int(x_train.shape[1]/3)\n",
    "col = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104000, 30, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], row, col)\n",
    "x_train = x_train.astype('float32')\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104000,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = datasetset[:,0]\n",
    "y_train = y_train.astype('int')\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104000, 8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np_utils.to_categorical(y_train, n_classes)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(CuDNNLSTM(units=256, input_shape=(row,col), return_sequences=True))\n",
    "model.add(CuDNNLSTM(units=128, return_sequences=True))\n",
    "model.add(CuDNNLSTM(units=64, return_sequences=True))\n",
    "model.add(CuDNNLSTM(units=32, return_sequences=True))\n",
    "model.add(CuDNNLSTM(units=16, return_sequences=True))\n",
    "model.add(CuDNNLSTM(units=8))\n",
    "model.add(Dense(units=n_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cu_dnnlstm_7 (CuDNNLSTM)     (None, 30, 256)           267264    \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_8 (CuDNNLSTM)     (None, 30, 128)           197632    \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_9 (CuDNNLSTM)     (None, 30, 64)            49664     \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_10 (CuDNNLSTM)    (None, 30, 32)            12544     \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_11 (CuDNNLSTM)    (None, 30, 16)            3200      \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_12 (CuDNNLSTM)    (None, 8)                 832       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 72        \n",
      "=================================================================\n",
      "Total params: 531,208\n",
      "Trainable params: 531,208\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "104000/104000 [==============================] - 3s 25us/step - loss: 0.0843 - acc: 0.9793\n",
      "Epoch 2/100\n",
      "104000/104000 [==============================] - 3s 25us/step - loss: 0.0879 - acc: 0.9772\n",
      "Epoch 3/100\n",
      "104000/104000 [==============================] - 3s 25us/step - loss: 0.0867 - acc: 0.9763\n",
      "Epoch 4/100\n",
      "104000/104000 [==============================] - 3s 25us/step - loss: 0.0870 - acc: 0.9763\n",
      "Epoch 5/100\n",
      "104000/104000 [==============================] - 3s 25us/step - loss: 0.0728 - acc: 0.9814\n",
      "Epoch 6/100\n",
      "104000/104000 [==============================] - 3s 25us/step - loss: 0.0722 - acc: 0.9812\n",
      "Epoch 7/100\n",
      "104000/104000 [==============================] - 3s 25us/step - loss: 0.0673 - acc: 0.9827\n",
      "Epoch 8/100\n",
      "104000/104000 [==============================] - 3s 25us/step - loss: 0.0706 - acc: 0.9807\n",
      "Epoch 9/100\n",
      "104000/104000 [==============================] - 3s 25us/step - loss: 0.0639 - acc: 0.9830\n",
      "Epoch 10/100\n",
      "104000/104000 [==============================] - 3s 25us/step - loss: 0.0636 - acc: 0.9833: 0s - loss: 0.0625 - acc: 0.9\n",
      "Epoch 11/100\n",
      "104000/104000 [==============================] - 3s 25us/step - loss: 0.0639 - acc: 0.9825\n",
      "Epoch 12/100\n",
      "104000/104000 [==============================] - 3s 25us/step - loss: 0.0643 - acc: 0.9822\n",
      "Epoch 13/100\n",
      "104000/104000 [==============================] - 3s 25us/step - loss: 0.0567 - acc: 0.9848\n",
      "Epoch 14/100\n",
      "104000/104000 [==============================] - 3s 25us/step - loss: 0.0568 - acc: 0.9845\n",
      "Epoch 15/100\n",
      "104000/104000 [==============================] - 3s 26us/step - loss: 0.0597 - acc: 0.9830\n",
      "Epoch 16/100\n",
      "104000/104000 [==============================] - 3s 25us/step - loss: 0.0611 - acc: 0.9824\n",
      "Epoch 17/100\n",
      "104000/104000 [==============================] - 3s 25us/step - loss: 0.0535 - acc: 0.9852\n",
      "Epoch 18/100\n",
      "104000/104000 [==============================] - 3s 25us/step - loss: 0.0531 - acc: 0.9852\n",
      "Epoch 19/100\n",
      "104000/104000 [==============================] - 3s 25us/step - loss: 0.0508 - acc: 0.9858\n",
      "Epoch 20/100\n",
      "104000/104000 [==============================] - 3s 25us/step - loss: 0.0569 - acc: 0.9832\n",
      "Epoch 21/100\n",
      "104000/104000 [==============================] - 3s 25us/step - loss: 1.7111 - acc: 0.6153\n",
      "Epoch 22/100\n",
      "104000/104000 [==============================] - 3s 25us/step - loss: 0.6905 - acc: 0.7835\n",
      "Epoch 23/100\n",
      "104000/104000 [==============================] - 3s 25us/step - loss: 0.3000 - acc: 0.9083\n",
      "Epoch 24/100\n",
      "104000/104000 [==============================] - 3s 25us/step - loss: 0.1938 - acc: 0.9474\n",
      "Epoch 25/100\n",
      "104000/104000 [==============================] - 3s 26us/step - loss: 0.1481 - acc: 0.9607\n",
      "Epoch 26/100\n",
      "104000/104000 [==============================] - 3s 25us/step - loss: 0.1242 - acc: 0.9678\n",
      "Epoch 27/100\n",
      "104000/104000 [==============================] - 3s 26us/step - loss: 0.1098 - acc: 0.9713\n",
      "Epoch 28/100\n",
      "104000/104000 [==============================] - 3s 25us/step - loss: 0.1000 - acc: 0.9742\n",
      "Epoch 29/100\n",
      "104000/104000 [==============================] - 3s 26us/step - loss: 0.0927 - acc: 0.9764\n",
      "Epoch 30/100\n",
      "104000/104000 [==============================] - 3s 26us/step - loss: 0.0880 - acc: 0.9770\n",
      "Epoch 31/100\n",
      "104000/104000 [==============================] - 3s 26us/step - loss: 0.0827 - acc: 0.9781\n",
      "Epoch 32/100\n",
      "104000/104000 [==============================] - 3s 26us/step - loss: 0.0764 - acc: 0.9805\n",
      "Epoch 33/100\n",
      "104000/104000 [==============================] - 3s 26us/step - loss: 0.0718 - acc: 0.9815\n",
      "Epoch 34/100\n",
      "104000/104000 [==============================] - 3s 25us/step - loss: 0.0682 - acc: 0.9826\n",
      "Epoch 35/100\n",
      "104000/104000 [==============================] - 3s 26us/step - loss: 0.0668 - acc: 0.9825\n",
      "Epoch 36/100\n",
      "104000/104000 [==============================] - 3s 25us/step - loss: 0.0645 - acc: 0.9828\n",
      "Epoch 37/100\n",
      "104000/104000 [==============================] - 3s 26us/step - loss: 0.0624 - acc: 0.9837\n",
      "Epoch 38/100\n",
      "104000/104000 [==============================] - 3s 25us/step - loss: 0.0575 - acc: 0.9852\n",
      "Epoch 39/100\n",
      "104000/104000 [==============================] - 3s 26us/step - loss: 0.0549 - acc: 0.9857\n",
      "Epoch 40/100\n",
      "104000/104000 [==============================] - 3s 25us/step - loss: 0.0531 - acc: 0.9868\n",
      "Epoch 41/100\n",
      "104000/104000 [==============================] - 3s 25us/step - loss: 0.0541 - acc: 0.9854\n",
      "Epoch 42/100\n",
      "104000/104000 [==============================] - 3s 25us/step - loss: 0.0526 - acc: 0.9863\n",
      "Epoch 43/100\n",
      "104000/104000 [==============================] - 3s 26us/step - loss: 0.0553 - acc: 0.9848\n",
      "Epoch 44/100\n",
      "104000/104000 [==============================] - 3s 26us/step - loss: 0.0516 - acc: 0.9860\n",
      "Epoch 45/100\n",
      "104000/104000 [==============================] - 3s 26us/step - loss: 0.0488 - acc: 0.9873\n",
      "Epoch 46/100\n",
      "104000/104000 [==============================] - 3s 25us/step - loss: 0.0510 - acc: 0.9864\n",
      "Epoch 47/100\n",
      "104000/104000 [==============================] - 3s 26us/step - loss: 0.0503 - acc: 0.9861\n",
      "Epoch 48/100\n",
      "104000/104000 [==============================] - 3s 25us/step - loss: 0.0493 - acc: 0.9865\n",
      "Epoch 49/100\n",
      "104000/104000 [==============================] - 3s 26us/step - loss: 0.0459 - acc: 0.9879\n",
      "Epoch 50/100\n",
      "104000/104000 [==============================] - 3s 26us/step - loss: 0.0451 - acc: 0.9880\n",
      "Epoch 51/100\n",
      "104000/104000 [==============================] - 3s 26us/step - loss: 0.0442 - acc: 0.9881\n",
      "Epoch 52/100\n",
      "104000/104000 [==============================] - 3s 25us/step - loss: 0.0439 - acc: 0.9880\n",
      "Epoch 53/100\n",
      "104000/104000 [==============================] - 3s 26us/step - loss: 0.0437 - acc: 0.9881\n",
      "Epoch 54/100\n",
      "104000/104000 [==============================] - 3s 26us/step - loss: 0.0431 - acc: 0.9881\n",
      "Epoch 55/100\n",
      "104000/104000 [==============================] - 3s 26us/step - loss: 0.0472 - acc: 0.9863\n",
      "Epoch 56/100\n",
      "104000/104000 [==============================] - 3s 26us/step - loss: 0.0486 - acc: 0.9860\n",
      "Epoch 57/100\n",
      "104000/104000 [==============================] - 3s 26us/step - loss: 0.0453 - acc: 0.9867\n",
      "Epoch 58/100\n",
      "104000/104000 [==============================] - 3s 25us/step - loss: 0.0533 - acc: 0.9841\n",
      "Epoch 59/100\n",
      "104000/104000 [==============================] - 3s 26us/step - loss: 0.0571 - acc: 0.9823\n",
      "Epoch 60/100\n",
      "104000/104000 [==============================] - 3s 26us/step - loss: 0.0469 - acc: 0.9863\n",
      "Epoch 61/100\n",
      "104000/104000 [==============================] - 3s 26us/step - loss: 0.0434 - acc: 0.9878\n",
      "Epoch 62/100\n",
      "104000/104000 [==============================] - 3s 26us/step - loss: 0.0402 - acc: 0.9888\n",
      "Epoch 63/100\n",
      "104000/104000 [==============================] - 3s 26us/step - loss: 0.0392 - acc: 0.9891\n",
      "Epoch 64/100\n",
      "104000/104000 [==============================] - 3s 26us/step - loss: 0.0395 - acc: 0.9891: 1s - loss: 0.0396 - acc\n",
      "Epoch 65/100\n",
      "104000/104000 [==============================] - 3s 25us/step - loss: 0.0419 - acc: 0.9880\n",
      "Epoch 66/100\n",
      "104000/104000 [==============================] - 3s 26us/step - loss: 0.0406 - acc: 0.9883\n",
      "Epoch 67/100\n",
      "104000/104000 [==============================] - 3s 26us/step - loss: 0.0392 - acc: 0.9887\n",
      "Epoch 68/100\n",
      "104000/104000 [==============================] - 3s 26us/step - loss: 0.0387 - acc: 0.9890\n",
      "Epoch 69/100\n",
      "104000/104000 [==============================] - 3s 26us/step - loss: 0.0407 - acc: 0.9882\n",
      "Epoch 70/100\n",
      "104000/104000 [==============================] - 3s 26us/step - loss: 0.0459 - acc: 0.9862\n",
      "Epoch 71/100\n",
      "104000/104000 [==============================] - 3s 26us/step - loss: 1.7262 - acc: 0.6524\n",
      "Epoch 72/100\n",
      "104000/104000 [==============================] - 3s 25us/step - loss: 0.5998 - acc: 0.8071\n",
      "Epoch 73/100\n",
      "104000/104000 [==============================] - 3s 26us/step - loss: 0.2932 - acc: 0.9057\n",
      "Epoch 74/100\n",
      "104000/104000 [==============================] - 3s 25us/step - loss: 0.1900 - acc: 0.9385\n",
      "Epoch 75/100\n",
      "104000/104000 [==============================] - 3s 26us/step - loss: 0.1439 - acc: 0.9550\n",
      "Epoch 76/100\n",
      "104000/104000 [==============================] - 3s 25us/step - loss: 0.1234 - acc: 0.9626\n",
      "Epoch 77/100\n",
      "104000/104000 [==============================] - 3s 25us/step - loss: 0.1091 - acc: 0.9682\n",
      "Epoch 78/100\n",
      "104000/104000 [==============================] - 3s 25us/step - loss: 0.0993 - acc: 0.9712\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104000/104000 [==============================] - 3s 25us/step - loss: 0.0881 - acc: 0.9754\n",
      "Epoch 80/100\n",
      "104000/104000 [==============================] - 3s 26us/step - loss: 0.0812 - acc: 0.9781\n",
      "Epoch 81/100\n",
      "104000/104000 [==============================] - 3s 25us/step - loss: 0.0764 - acc: 0.9790\n",
      "Epoch 82/100\n",
      "104000/104000 [==============================] - 3s 26us/step - loss: 0.0709 - acc: 0.9806\n",
      "Epoch 83/100\n",
      "104000/104000 [==============================] - 3s 26us/step - loss: 0.0685 - acc: 0.9811\n",
      "Epoch 84/100\n",
      "104000/104000 [==============================] - 3s 26us/step - loss: 0.0646 - acc: 0.9821\n",
      "Epoch 85/100\n",
      "104000/104000 [==============================] - 3s 25us/step - loss: 0.0615 - acc: 0.9833\n",
      "Epoch 86/100\n",
      "104000/104000 [==============================] - 3s 26us/step - loss: 0.0613 - acc: 0.9832\n",
      "Epoch 87/100\n",
      "104000/104000 [==============================] - 3s 25us/step - loss: 0.0587 - acc: 0.9837\n",
      "Epoch 88/100\n",
      "104000/104000 [==============================] - 3s 26us/step - loss: 0.0537 - acc: 0.9851\n",
      "Epoch 89/100\n",
      "104000/104000 [==============================] - 3s 25us/step - loss: 0.0527 - acc: 0.9855\n",
      "Epoch 90/100\n",
      "104000/104000 [==============================] - 3s 26us/step - loss: 0.0501 - acc: 0.9863\n",
      "Epoch 91/100\n",
      "104000/104000 [==============================] - 3s 25us/step - loss: 0.0489 - acc: 0.9866\n",
      "Epoch 92/100\n",
      "104000/104000 [==============================] - 3s 26us/step - loss: 0.0468 - acc: 0.9874\n",
      "Epoch 93/100\n",
      "104000/104000 [==============================] - 3s 26us/step - loss: 0.0457 - acc: 0.9879\n",
      "Epoch 94/100\n",
      "104000/104000 [==============================] - 3s 25us/step - loss: 0.0453 - acc: 0.9879\n",
      "Epoch 95/100\n",
      "104000/104000 [==============================] - 3s 25us/step - loss: 0.0515 - acc: 0.9852\n",
      "Epoch 96/100\n",
      "104000/104000 [==============================] - 3s 25us/step - loss: 0.0454 - acc: 0.9872\n",
      "Epoch 97/100\n",
      "104000/104000 [==============================] - 3s 25us/step - loss: 0.0432 - acc: 0.9881\n",
      "Epoch 98/100\n",
      "104000/104000 [==============================] - 3s 25us/step - loss: 0.0433 - acc: 0.9882\n",
      "Epoch 99/100\n",
      "104000/104000 [==============================] - 3s 25us/step - loss: 0.0468 - acc: 0.9865\n",
      "Epoch 100/100\n",
      "104000/104000 [==============================] - 3s 25us/step - loss: 0.0441 - acc: 0.9876\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "batch_size = 8000\n",
    "training_iters = 100\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=training_iters, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_acc(direction, speed):\n",
    "    speed = str(speed)\n",
    "    file = './datasets/split by random for distributed//classification/' +  direction + speed + '_test.csv'\n",
    "    test_up2 = pd.read_csv(file, header=None)\n",
    "    test_up2 = test_up2.fillna(0)\n",
    "    test_up2 = np.array(test_up2)\n",
    "    test_up2 = test_up2.reshape(test_up2.shape[0],row,col)\n",
    "    cnt = np.array([0,0,0,0,0,0,0,0])\n",
    "    pred = model.predict(test_up2)\n",
    "    for i in range (pred.shape[0]):\n",
    "        for j in range (8):\n",
    "            if max(pred[i,:]) == pred[i,j]:\n",
    "                cnt[j] += 1\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[242.,   8.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  5., 242.,   0.,   0.,   0.,   2.,   0.,   1.],\n",
       "       [  1.,   0., 248.,   1.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   1., 248.,   0.,   0.,   1.,   0.],\n",
       "       [  0.,   0.,   0.,   0., 249.,   1.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   1., 249.,   0.,   0.],\n",
       "       [  0.,   0.,   2.,   3.,   0.,   0., 245.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   1.,   0., 249.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuarcy = np.zeros([8,8])\n",
    "accuarcy[0,:] = cal_acc('top', 5)\n",
    "accuarcy[1,:] = cal_acc('top', 6)\n",
    "accuarcy[2,:] = cal_acc('left', 5)\n",
    "accuarcy[3,:] = cal_acc('left', 6)\n",
    "accuarcy[4,:] = cal_acc('right', 5)\n",
    "accuarcy[5,:] = cal_acc('right', 6)\n",
    "accuarcy[6,:] = cal_acc('back', 5)\n",
    "accuarcy[7,:] = cal_acc('back', 6)\n",
    "accuarcy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 90)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top5_test = pd.read_csv('./datasets/split by random for distributed/classification/top5_test.csv', header=None)\n",
    "top5_test = np.array(top5_test)\n",
    "top5_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.00000473 0.00138889 0.00030746 0.00170388 0.000074   0.0072361\n",
      "  0.00005108 0.98923385]]\n",
      "6.0\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[0.00000287 0.00003515 0.00000759 0.00022662 0.00736504 0.990824\n",
      "  0.0007709  0.00076775]]\n",
      "7.0\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[0.00011106 0.00134138 0.00003557 0.00007222 0.4317555  0.548493\n",
      "  0.01776781 0.00042344]]\n",
      "8.0\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[0.46385917 0.00224992 0.00185253 0.00025418 0.03963166 0.00062429\n",
      "  0.49151167 0.00001657]]\n",
      "9.0\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[0.98492485 0.00026195 0.00574772 0.00009056 0.00069688 0.00000312\n",
      "  0.00827379 0.00000112]]\n",
      "10.0\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[0.9827691  0.000274   0.0063886  0.00010529 0.00079356 0.00000383\n",
      "  0.00966428 0.00000135]]\n",
      "11.0\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[0.9753475  0.00037235 0.00902821 0.00016068 0.00132964 0.00000793\n",
      "  0.01375087 0.00000293]]\n",
      "12.0\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[0.9692637  0.00043437 0.01200196 0.00020891 0.00183508 0.00001228\n",
      "  0.01623902 0.00000481]]\n",
      "13.0\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[0.9675271  0.00044253 0.01299851 0.00022118 0.00196378 0.00001339\n",
      "  0.01682812 0.00000536]]\n",
      "14.0\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[0.9779352  0.00032497 0.00832029 0.00014068 0.00110269 0.00000609\n",
      "  0.01216774 0.00000225]]\n",
      "15.0\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[0.9834009  0.00025533 0.00658419 0.00010203 0.00073438 0.00000342\n",
      "  0.00891851 0.00000126]]\n",
      "16.0\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[0.98535246 0.0002427  0.00610278 0.00009211 0.0006293  0.00000278\n",
      "  0.00757688 0.00000106]]\n",
      "17.0\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[0.98704207 0.00026935 0.00560536 0.00009018 0.00057161 0.00000253\n",
      "  0.00641781 0.00000104]]\n",
      "18.0\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[0.9885019  0.00036055 0.00503213 0.00009785 0.00054488 0.00000255\n",
      "  0.00545887 0.00000118]]\n",
      "19.0\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[0.990225   0.00078403 0.0040839  0.00013302 0.00055582 0.00000305\n",
      "  0.00421354 0.00000169]]\n",
      "20.0\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[0.99033725 0.00210911 0.00334699 0.00021075 0.00064176 0.0000042\n",
      "  0.00334737 0.00000258]]\n",
      "21.0\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[0.9891833  0.00372744 0.00306079 0.00027976 0.00073248 0.00000524\n",
      "  0.00300769 0.00000325]]\n",
      "22.0\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[0.9888889  0.00412606 0.00298446 0.00030008 0.00070941 0.00000521\n",
      "  0.00298251 0.00000335]]\n",
      "23.0\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[0.9880235  0.00507596 0.0029021  0.00033971 0.00072852 0.00000554\n",
      "  0.00292107 0.0000036 ]]\n",
      "24.0\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[0.9859783  0.00719716 0.00279521 0.00041309 0.00079965 0.00000642\n",
      "  0.00280594 0.00000413]]\n",
      "25.0\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[0.9843268  0.00888629 0.00273415 0.00046156 0.00085478 0.00000709\n",
      "  0.0027248  0.00000452]]\n",
      "26.0\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[0.9840267  0.0091989  0.00272209 0.00046921 0.00086363 0.00000722\n",
      "  0.00270761 0.00000461]]\n",
      "27.0\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[0.98398244 0.00924824 0.00271911 0.00046988 0.00086557 0.00000725\n",
      "  0.00270281 0.00000463]]\n",
      "28.0\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[0.9839824  0.00925036 0.00271813 0.00046962 0.00086612 0.00000725\n",
      "  0.00270146 0.00000463]]\n",
      "29.0\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[0.98398584 0.0092472  0.00271787 0.00046941 0.00086647 0.00000726\n",
      "  0.00270127 0.00000463]]\n",
      "30.0\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[0.98398685 0.00924625 0.00271784 0.00046936 0.0008666  0.00000726\n",
      "  0.00270132 0.00000463]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "for i in range(14,90,3):\n",
    "    tmp = top5_test[1,:i]\n",
    "    tmp = tmp.reshape(1, tmp.shape[0])\n",
    "    tmp = sequence.pad_sequences(tmp, maxlen=(row*col), padding='post', dtype='float32')\n",
    "    tmp = tmp.reshape(1, 30, 3)\n",
    "    print((i+1)/3)\n",
    "    preddd = model.predict(tmp, verbose=1)\n",
    "    print(preddd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('./classification_notfixed_20200505_256to8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
