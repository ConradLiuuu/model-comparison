{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/lab606a/.virtualenvs/keras/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/lab606a/.virtualenvs/keras/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/lab606a/.virtualenvs/keras/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/lab606a/.virtualenvs/keras/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/lab606a/.virtualenvs/keras/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/lab606a/.virtualenvs/keras/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "## import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Activation, TimeDistributed, RepeatVector, Bidirectional, CuDNNLSTM\n",
    "import matplotlib.pyplot as plt\n",
    "#import os\n",
    "import tensorflow as tf\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set GPU memory\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_step = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(data, depth):\n",
    "    dataset = data\n",
    "    depth = depth\n",
    "    X = np.zeros([int(depth), n_step, 3])\n",
    "    Y = np.zeros([int(depth), n_step, 3])\n",
    "    c = 0\n",
    "    d = 0\n",
    "    \n",
    "    for i in range(int(depth)):\n",
    "        for j in range(n_step):\n",
    "            if d < dataset.shape[0]:\n",
    "                X[i,j,:] = dataset[d, c:c+3]\n",
    "                Y[i,j,:] = dataset[d, (c+3*n_step):(c+3*n_step+3)]\n",
    "                \n",
    "                if ((c+3*n_step+3) != (dataset.shape[1])):\n",
    "                    c +=3\n",
    "                else:\n",
    "                    c = 0\n",
    "                    d += 1\n",
    "        if (c-3) > 0:\n",
    "            c = (c - 3*n_step + 3)\n",
    "        else:\n",
    "            c = c\n",
    "            \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1642, 147)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('/home/lab606a/Documents/20200415/not_fixed/datasets/test.csv', header=None)\n",
    "dataset = dataset.fillna(0)\n",
    "dataset = np.array(dataset)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen_train = dataset.shape[1]+(n_step-1)*3\n",
    "maxlen_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1642, 171)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = sequence.pad_sequences(dataset, maxlen=maxlen_train, padding='post', dtype='float32')\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_train = (int(dataset.shape[1]/3)+1-n_step-n_step)*dataset.shape[0] # (all_balls + 1 - input_balls - output_balls)*n_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = split(data=dataset, depth=depth_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(CuDNNLSTM(128, input_shape=(x_train.shape[1], x_train.shape[2]), kernel_regularizer=l2(0.01)))\n",
    "model.add(RepeatVector(x_train.shape[1]))\n",
    "model.add(CuDNNLSTM(128, return_sequences=True ,activity_regularizer=l2(0.01)))\n",
    "model.add(TimeDistributed(Dense(3)))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cu_dnnlstm_1 (CuDNNLSTM)     (None, 128)               68096     \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 9, 128)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_2 (CuDNNLSTM)     (None, 9, 128)            132096    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 9, 3)              387       \n",
      "=================================================================\n",
      "Total params: 200,579\n",
      "Trainable params: 200,579\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 5.5691 - acc: 0.7956\n",
      "Epoch 2/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.8938 - acc: 0.8023\n",
      "Epoch 3/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.4206 - acc: 0.8087\n",
      "Epoch 4/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 4.4332 - acc: 0.7977\n",
      "Epoch 5/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 4.3246 - acc: 0.8061\n",
      "Epoch 6/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.2051 - acc: 0.8104\n",
      "Epoch 7/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 4.0412 - acc: 0.8569\n",
      "Epoch 8/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 4.0103 - acc: 0.8783\n",
      "Epoch 9/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 4.0439 - acc: 0.8776\n",
      "Epoch 10/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 4.0044 - acc: 0.8877\n",
      "Epoch 11/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 3.9837 - acc: 0.8666\n",
      "Epoch 12/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 4.0602 - acc: 0.8956\n",
      "Epoch 13/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.0071 - acc: 0.8830\n",
      "Epoch 14/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.9831 - acc: 0.8906\n",
      "Epoch 15/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.9786 - acc: 0.8862\n",
      "Epoch 16/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.9676 - acc: 0.8965\n",
      "Epoch 17/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.9607 - acc: 0.8746\n",
      "Epoch 18/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.9677 - acc: 0.8904\n",
      "Epoch 19/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.0062 - acc: 0.8605\n",
      "Epoch 20/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.0132 - acc: 0.8762\n",
      "Epoch 21/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 4.0055 - acc: 0.8943\n",
      "Epoch 22/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 4.0168 - acc: 0.8589\n",
      "Epoch 23/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.0186 - acc: 0.8662\n",
      "Epoch 24/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.1714 - acc: 0.8487\n",
      "Epoch 25/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.5483 - acc: 0.8009\n",
      "Epoch 26/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.9623 - acc: 0.8202\n",
      "Epoch 27/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.7837 - acc: 0.7958\n",
      "Epoch 28/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 5.0396 - acc: 0.7965\n",
      "Epoch 29/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 4.9854 - acc: 0.8200\n",
      "Epoch 30/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 5.3800 - acc: 0.8070\n",
      "Epoch 31/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.5921 - acc: 0.7933\n",
      "Epoch 32/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 4.1450 - acc: 0.8354\n",
      "Epoch 33/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 4.1160 - acc: 0.8473\n",
      "Epoch 34/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.2135 - acc: 0.8364\n",
      "Epoch 35/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 4.6205 - acc: 0.7989\n",
      "Epoch 36/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 4.4989 - acc: 0.7889\n",
      "Epoch 37/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 4.8278 - acc: 0.8092\n",
      "Epoch 38/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 5.4067 - acc: 0.7840\n",
      "Epoch 39/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 4.4867 - acc: 0.7976\n",
      "Epoch 40/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.8566 - acc: 0.8262\n",
      "Epoch 41/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.9701 - acc: 0.8057\n",
      "Epoch 42/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.2093 - acc: 0.7971\n",
      "Epoch 43/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.0736 - acc: 0.8412\n",
      "Epoch 44/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 3.9812 - acc: 0.8685\n",
      "Epoch 45/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 4.0078 - acc: 0.8621\n",
      "Epoch 46/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.9812 - acc: 0.8461\n",
      "Epoch 47/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.9944 - acc: 0.8782\n",
      "Epoch 48/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.0108 - acc: 0.8714\n",
      "Epoch 49/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.9456 - acc: 0.8930\n",
      "Epoch 50/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.9536 - acc: 0.8672\n",
      "Epoch 51/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.9408 - acc: 0.8574\n",
      "Epoch 52/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.9581 - acc: 0.8643\n",
      "Epoch 53/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 3.9512 - acc: 0.8457\n",
      "Epoch 54/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 4.0129 - acc: 0.8638\n",
      "Epoch 55/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.0143 - acc: 0.8467\n",
      "Epoch 56/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.1045 - acc: 0.8494\n",
      "Epoch 57/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.0149 - acc: 0.8536\n",
      "Epoch 58/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.9865 - acc: 0.8808\n",
      "Epoch 59/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.9888 - acc: 0.8445\n",
      "Epoch 60/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.0308 - acc: 0.8588\n",
      "Epoch 61/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.0391 - acc: 0.8487\n",
      "Epoch 62/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 5.2428 - acc: 0.8066\n",
      "Epoch 63/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 5.8786 - acc: 0.8084\n",
      "Epoch 64/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 5.2272 - acc: 0.7900\n",
      "Epoch 65/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.8728 - acc: 0.8100\n",
      "Epoch 66/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.8438 - acc: 0.8178\n",
      "Epoch 67/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.7341 - acc: 0.8269\n",
      "Epoch 68/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.9843 - acc: 0.7849\n",
      "Epoch 69/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.5236 - acc: 0.8042\n",
      "Epoch 70/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 4.8454 - acc: 0.8103\n",
      "Epoch 71/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 4.7230 - acc: 0.7927\n",
      "Epoch 72/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 4.5589 - acc: 0.7931\n",
      "Epoch 73/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.2769 - acc: 0.7889\n",
      "Epoch 74/1000\n",
      "65680/65680 [==============================] - 1s 9us/step - loss: 4.0736 - acc: 0.8152\n",
      "Epoch 75/1000\n",
      "65680/65680 [==============================] - 1s 9us/step - loss: 4.0260 - acc: 0.8599\n",
      "Epoch 76/1000\n",
      "65680/65680 [==============================] - 1s 9us/step - loss: 3.9689 - acc: 0.8631\n",
      "Epoch 77/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.9586 - acc: 0.8498\n",
      "Epoch 78/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.9737 - acc: 0.8666\n",
      "Epoch 79/1000\n",
      "65680/65680 [==============================] - 1s 9us/step - loss: 4.0202 - acc: 0.8485\n",
      "Epoch 80/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 4.0239 - acc: 0.8497\n",
      "Epoch 81/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65680/65680 [==============================] - 1s 9us/step - loss: 3.9644 - acc: 0.8606\n",
      "Epoch 82/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 3.9866 - acc: 0.8693\n",
      "Epoch 83/1000\n",
      "65680/65680 [==============================] - 1s 9us/step - loss: 4.0544 - acc: 0.8336\n",
      "Epoch 84/1000\n",
      "65680/65680 [==============================] - 1s 9us/step - loss: 4.0212 - acc: 0.8403\n",
      "Epoch 85/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 4.1012 - acc: 0.8408\n",
      "Epoch 86/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 4.3168 - acc: 0.8121\n",
      "Epoch 87/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.1539 - acc: 0.8114\n",
      "Epoch 88/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 4.3001 - acc: 0.8074\n",
      "Epoch 89/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 4.2149 - acc: 0.8441\n",
      "Epoch 90/1000\n",
      "65680/65680 [==============================] - 1s 9us/step - loss: 4.2444 - acc: 0.8062\n",
      "Epoch 91/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.4321 - acc: 0.8057\n",
      "Epoch 92/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.5071 - acc: 0.7985\n",
      "Epoch 93/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 5.2257 - acc: 0.7950\n",
      "Epoch 94/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 4.6084 - acc: 0.8148\n",
      "Epoch 95/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 4.7734 - acc: 0.7913\n",
      "Epoch 96/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.9446 - acc: 0.7965\n",
      "Epoch 97/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 4.6140 - acc: 0.8102\n",
      "Epoch 98/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 4.6542 - acc: 0.7860\n",
      "Epoch 99/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 4.7122 - acc: 0.8174\n",
      "Epoch 100/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.6583 - acc: 0.7967\n",
      "Epoch 101/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.2835 - acc: 0.7979\n",
      "Epoch 102/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.2098 - acc: 0.8060\n",
      "Epoch 103/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.2296 - acc: 0.8372\n",
      "Epoch 104/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.0653 - acc: 0.8383\n",
      "Epoch 105/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.3583 - acc: 0.8230\n",
      "Epoch 106/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 4.6739 - acc: 0.8136\n",
      "Epoch 107/1000\n",
      "65680/65680 [==============================] - 1s 9us/step - loss: 4.8174 - acc: 0.8116\n",
      "Epoch 108/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 5.2210 - acc: 0.8203\n",
      "Epoch 109/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 4.9780 - acc: 0.8223\n",
      "Epoch 110/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.5952 - acc: 0.8006\n",
      "Epoch 111/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.1538 - acc: 0.8006\n",
      "Epoch 112/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.0448 - acc: 0.8190\n",
      "Epoch 113/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.1791 - acc: 0.8321\n",
      "Epoch 114/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.3775 - acc: 0.7809\n",
      "Epoch 115/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.4264 - acc: 0.7734\n",
      "Epoch 116/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.3496 - acc: 0.8256\n",
      "Epoch 117/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.1969 - acc: 0.7965\n",
      "Epoch 118/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.9922 - acc: 0.8391\n",
      "Epoch 119/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.9519 - acc: 0.8644\n",
      "Epoch 120/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.9401 - acc: 0.8664\n",
      "Epoch 121/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.8928 - acc: 0.8677\n",
      "Epoch 122/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.8861 - acc: 0.8902\n",
      "Epoch 123/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.9315 - acc: 0.8818\n",
      "Epoch 124/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 3.9225 - acc: 0.8966\n",
      "Epoch 125/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 3.8649 - acc: 0.8772\n",
      "Epoch 126/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.8580 - acc: 0.8585\n",
      "Epoch 127/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.8434 - acc: 0.8855\n",
      "Epoch 128/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 3.8559 - acc: 0.8779\n",
      "Epoch 129/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 3.8967 - acc: 0.8778\n",
      "Epoch 130/1000\n",
      "65680/65680 [==============================] - 1s 9us/step - loss: 3.8980 - acc: 0.8766\n",
      "Epoch 131/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 3.8477 - acc: 0.8640\n",
      "Epoch 132/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.8935 - acc: 0.8661\n",
      "Epoch 133/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.8775 - acc: 0.8722\n",
      "Epoch 134/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.9483 - acc: 0.8731\n",
      "Epoch 135/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.8517 - acc: 0.8733\n",
      "Epoch 136/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.8427 - acc: 0.8693\n",
      "Epoch 137/1000\n",
      "65680/65680 [==============================] - 0s 8us/step - loss: 3.8414 - acc: 0.8722\n",
      "Epoch 138/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.8809 - acc: 0.8800\n",
      "Epoch 139/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.8338 - acc: 0.8803\n",
      "Epoch 140/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.8597 - acc: 0.8781\n",
      "Epoch 141/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.8627 - acc: 0.8698\n",
      "Epoch 142/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.9054 - acc: 0.8534\n",
      "Epoch 143/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.8442 - acc: 0.8531\n",
      "Epoch 144/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 3.8738 - acc: 0.8432\n",
      "Epoch 145/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 3.8644 - acc: 0.8841\n",
      "Epoch 146/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 3.8471 - acc: 0.8525\n",
      "Epoch 147/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.9267 - acc: 0.8523\n",
      "Epoch 148/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.8589 - acc: 0.8640\n",
      "Epoch 149/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.0006 - acc: 0.8532\n",
      "Epoch 150/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 5.4879 - acc: 0.7869\n",
      "Epoch 151/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 5.6949 - acc: 0.8058\n",
      "Epoch 152/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 5.2505 - acc: 0.7984\n",
      "Epoch 153/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 5.1866 - acc: 0.7818\n",
      "Epoch 154/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 5.8399 - acc: 0.8097\n",
      "Epoch 155/1000\n",
      "65680/65680 [==============================] - 1s 10us/step - loss: 5.1897 - acc: 0.7796\n",
      "Epoch 156/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.7189 - acc: 0.8276\n",
      "Epoch 157/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 4.6974 - acc: 0.7952\n",
      "Epoch 158/1000\n",
      "65680/65680 [==============================] - 1s 9us/step - loss: 4.7208 - acc: 0.8005\n",
      "Epoch 159/1000\n",
      "65680/65680 [==============================] - 1s 9us/step - loss: 5.0732 - acc: 0.8313\n",
      "Epoch 160/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.8698 - acc: 0.8124\n",
      "Epoch 161/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 4.7701 - acc: 0.8093\n",
      "Epoch 162/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.8095 - acc: 0.8081\n",
      "Epoch 163/1000\n",
      "65680/65680 [==============================] - 1s 9us/step - loss: 4.4391 - acc: 0.7816\n",
      "Epoch 164/1000\n",
      "65680/65680 [==============================] - 1s 9us/step - loss: 4.2584 - acc: 0.8231\n",
      "Epoch 165/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 4.4163 - acc: 0.7981\n",
      "Epoch 166/1000\n",
      "65680/65680 [==============================] - 1s 9us/step - loss: 4.9304 - acc: 0.8087\n",
      "Epoch 167/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 4.5323 - acc: 0.8058\n",
      "Epoch 168/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.0384 - acc: 0.8294\n",
      "Epoch 169/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.9310 - acc: 0.8246\n",
      "Epoch 170/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.8562 - acc: 0.8678\n",
      "Epoch 171/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.8417 - acc: 0.8632\n",
      "Epoch 172/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.8256 - acc: 0.8785\n",
      "Epoch 173/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.8626 - acc: 0.8710\n",
      "Epoch 174/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.8540 - acc: 0.8687\n",
      "Epoch 175/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.8601 - acc: 0.8702\n",
      "Epoch 176/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.8785 - acc: 0.8620\n",
      "Epoch 177/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 3.8782 - acc: 0.8723\n",
      "Epoch 178/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 3.8544 - acc: 0.8832\n",
      "Epoch 179/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.8010 - acc: 0.8859\n",
      "Epoch 180/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.8019 - acc: 0.8796\n",
      "Epoch 181/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.8468 - acc: 0.8581\n",
      "Epoch 182/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.8961 - acc: 0.8501\n",
      "Epoch 183/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 4.0743 - acc: 0.8137\n",
      "Epoch 184/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.3433 - acc: 0.8072\n",
      "Epoch 185/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.3856 - acc: 0.8323\n",
      "Epoch 186/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.7395 - acc: 0.8017\n",
      "Epoch 187/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.4042 - acc: 0.8081\n",
      "Epoch 188/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.4084 - acc: 0.7975\n",
      "Epoch 189/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.9572 - acc: 0.7906\n",
      "Epoch 190/1000\n",
      "65680/65680 [==============================] - 1s 9us/step - loss: 4.5149 - acc: 0.8243\n",
      "Epoch 191/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.7099 - acc: 0.8064\n",
      "Epoch 192/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.6710 - acc: 0.8121\n",
      "Epoch 193/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.7219 - acc: 0.7830\n",
      "Epoch 194/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.3921 - acc: 0.7966\n",
      "Epoch 195/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.2059 - acc: 0.8444\n",
      "Epoch 196/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.5083 - acc: 0.7796\n",
      "Epoch 197/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.8688 - acc: 0.8002\n",
      "Epoch 198/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.4115 - acc: 0.7845\n",
      "Epoch 199/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.3040 - acc: 0.8141\n",
      "Epoch 200/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.2411 - acc: 0.7869\n",
      "Epoch 201/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.0771 - acc: 0.7924\n",
      "Epoch 202/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.5164 - acc: 0.7900\n",
      "Epoch 203/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 4.3648 - acc: 0.7991\n",
      "Epoch 204/1000\n",
      "65680/65680 [==============================] - 0s 8us/step - loss: 4.2521 - acc: 0.8163\n",
      "Epoch 205/1000\n",
      "65680/65680 [==============================] - 1s 9us/step - loss: 4.8477 - acc: 0.8055\n",
      "Epoch 206/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.5499 - acc: 0.7713\n",
      "Epoch 207/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 4.0134 - acc: 0.8208\n",
      "Epoch 208/1000\n",
      "65680/65680 [==============================] - 1s 9us/step - loss: 3.9031 - acc: 0.8441\n",
      "Epoch 209/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 3.8644 - acc: 0.8610\n",
      "Epoch 210/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.8157 - acc: 0.8839\n",
      "Epoch 211/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.8025 - acc: 0.8685\n",
      "Epoch 212/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.8293 - acc: 0.8842\n",
      "Epoch 213/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.7901 - acc: 0.8744\n",
      "Epoch 214/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.7725 - acc: 0.8689\n",
      "Epoch 215/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.7834 - acc: 0.8734\n",
      "Epoch 216/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.7745 - acc: 0.8771\n",
      "Epoch 217/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.7919 - acc: 0.8956\n",
      "Epoch 218/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.8237 - acc: 0.8716\n",
      "Epoch 219/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.7726 - acc: 0.8620\n",
      "Epoch 220/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.7715 - acc: 0.8773\n",
      "Epoch 221/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.8683 - acc: 0.8722\n",
      "Epoch 222/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 3.8546 - acc: 0.8679\n",
      "Epoch 223/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 3.8019 - acc: 0.8830\n",
      "Epoch 224/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 3.7491 - acc: 0.8571\n",
      "Epoch 225/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 3.8361 - acc: 0.8646\n",
      "Epoch 226/1000\n",
      "65680/65680 [==============================] - 1s 9us/step - loss: 3.7646 - acc: 0.8711\n",
      "Epoch 227/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 3.7473 - acc: 0.8852\n",
      "Epoch 228/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.7896 - acc: 0.8741\n",
      "Epoch 229/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.7498 - acc: 0.8818\n",
      "Epoch 230/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.7756 - acc: 0.8780\n",
      "Epoch 231/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.8198 - acc: 0.8589\n",
      "Epoch 232/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.8102 - acc: 0.8755\n",
      "Epoch 233/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.8742 - acc: 0.8630\n",
      "Epoch 234/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.8067 - acc: 0.8598\n",
      "Epoch 235/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.0090 - acc: 0.8393\n",
      "Epoch 236/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.0216 - acc: 0.8139\n",
      "Epoch 237/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 4.1288 - acc: 0.8033\n",
      "Epoch 238/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 6.0667 - acc: 0.7997\n",
      "Epoch 239/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65680/65680 [==============================] - 0s 4us/step - loss: 5.2179 - acc: 0.7855\n",
      "Epoch 240/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 5.7104 - acc: 0.7911\n",
      "Epoch 241/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 5.7503 - acc: 0.7826\n",
      "Epoch 242/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 5.4450 - acc: 0.7917\n",
      "Epoch 243/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.7455 - acc: 0.8050\n",
      "Epoch 244/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.4069 - acc: 0.8000\n",
      "Epoch 245/1000\n",
      "65680/65680 [==============================] - 0s 8us/step - loss: 4.0865 - acc: 0.7800\n",
      "Epoch 246/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 3.9699 - acc: 0.8192\n",
      "Epoch 247/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.9362 - acc: 0.8119\n",
      "Epoch 248/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 3.9992 - acc: 0.8415\n",
      "Epoch 249/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 3.9096 - acc: 0.8198\n",
      "Epoch 250/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 3.8782 - acc: 0.8393\n",
      "Epoch 251/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 4.0587 - acc: 0.7969\n",
      "Epoch 252/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 4.3389 - acc: 0.8142\n",
      "Epoch 253/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.6578 - acc: 0.7726\n",
      "Epoch 254/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.4075 - acc: 0.7737\n",
      "Epoch 255/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 5.1924 - acc: 0.7915\n",
      "Epoch 256/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 4.5731 - acc: 0.7974\n",
      "Epoch 257/1000\n",
      "65680/65680 [==============================] - 0s 8us/step - loss: 4.1935 - acc: 0.8208\n",
      "Epoch 258/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.2598 - acc: 0.7891\n",
      "Epoch 259/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.0664 - acc: 0.8110\n",
      "Epoch 260/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.9328 - acc: 0.8167\n",
      "Epoch 261/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.9862 - acc: 0.8209\n",
      "Epoch 262/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.0799 - acc: 0.7952\n",
      "Epoch 263/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 3.9559 - acc: 0.8173\n",
      "Epoch 264/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.8534 - acc: 0.8151\n",
      "Epoch 265/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 3.8776 - acc: 0.8139A: 0s - loss: 3.9445 - acc: 0\n",
      "Epoch 266/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 3.8580 - acc: 0.8449\n",
      "Epoch 267/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.8600 - acc: 0.8580\n",
      "Epoch 268/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.8149 - acc: 0.8420\n",
      "Epoch 269/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.7973 - acc: 0.8290\n",
      "Epoch 270/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.8560 - acc: 0.8250\n",
      "Epoch 271/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.4154 - acc: 0.8272\n",
      "Epoch 272/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.7873 - acc: 0.7887\n",
      "Epoch 273/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.6553 - acc: 0.7900\n",
      "Epoch 274/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.4214 - acc: 0.8084\n",
      "Epoch 275/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.5075 - acc: 0.8192\n",
      "Epoch 276/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.7433 - acc: 0.7986\n",
      "Epoch 277/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.6398 - acc: 0.8031\n",
      "Epoch 278/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 4.2426 - acc: 0.7806\n",
      "Epoch 279/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 3.8821 - acc: 0.8473\n",
      "Epoch 280/1000\n",
      "65680/65680 [==============================] - 1s 9us/step - loss: 3.8966 - acc: 0.8307\n",
      "Epoch 281/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.8440 - acc: 0.8512\n",
      "Epoch 282/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.8256 - acc: 0.8656\n",
      "Epoch 283/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 3.8337 - acc: 0.8488\n",
      "Epoch 284/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 3.7873 - acc: 0.8425\n",
      "Epoch 285/1000\n",
      "65680/65680 [==============================] - 0s 8us/step - loss: 4.0025 - acc: 0.8127\n",
      "Epoch 286/1000\n",
      "65680/65680 [==============================] - 1s 9us/step - loss: 4.7030 - acc: 0.8126\n",
      "Epoch 287/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 4.9299 - acc: 0.7714\n",
      "Epoch 288/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.1270 - acc: 0.7966\n",
      "Epoch 289/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.0046 - acc: 0.8046\n",
      "Epoch 290/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 4.1052 - acc: 0.7816\n",
      "Epoch 291/1000\n",
      "65680/65680 [==============================] - 1s 9us/step - loss: 4.0939 - acc: 0.8116\n",
      "Epoch 292/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 4.0546 - acc: 0.8346\n",
      "Epoch 293/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.9174 - acc: 0.8222\n",
      "Epoch 294/1000\n",
      "65680/65680 [==============================] - 1s 9us/step - loss: 3.7659 - acc: 0.8536\n",
      "Epoch 295/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 3.7500 - acc: 0.8605\n",
      "Epoch 296/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 3.8729 - acc: 0.8472\n",
      "Epoch 297/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 4.0112 - acc: 0.8468\n",
      "Epoch 298/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.3546 - acc: 0.8004\n",
      "Epoch 299/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 4.3828 - acc: 0.7986\n",
      "Epoch 300/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 4.4058 - acc: 0.8126\n",
      "Epoch 301/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 4.7547 - acc: 0.7947\n",
      "Epoch 302/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.5615 - acc: 0.8222\n",
      "Epoch 303/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 4.6996 - acc: 0.7743\n",
      "Epoch 304/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.3863 - acc: 0.8240\n",
      "Epoch 305/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.0470 - acc: 0.8116\n",
      "Epoch 306/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.2452 - acc: 0.8137\n",
      "Epoch 307/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.9551 - acc: 0.8026\n",
      "Epoch 308/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.8782 - acc: 0.8194\n",
      "Epoch 309/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.9500 - acc: 0.8424\n",
      "Epoch 310/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.8806 - acc: 0.8600\n",
      "Epoch 311/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.1020 - acc: 0.7988\n",
      "Epoch 312/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 4.3874 - acc: 0.8163\n",
      "Epoch 313/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.3702 - acc: 0.7879\n",
      "Epoch 314/1000\n",
      "65680/65680 [==============================] - 1s 9us/step - loss: 4.4797 - acc: 0.7836\n",
      "Epoch 315/1000\n",
      "65680/65680 [==============================] - 1s 9us/step - loss: 4.2542 - acc: 0.8127\n",
      "Epoch 316/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 3.9715 - acc: 0.8049\n",
      "Epoch 317/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 4.1763 - acc: 0.8020\n",
      "Epoch 318/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65680/65680 [==============================] - 0s 5us/step - loss: 5.0936 - acc: 0.7883\n",
      "Epoch 319/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.4052 - acc: 0.8109\n",
      "Epoch 320/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.1276 - acc: 0.7999\n",
      "Epoch 321/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.9677 - acc: 0.8181\n",
      "Epoch 322/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.0264 - acc: 0.7996\n",
      "Epoch 323/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.8813 - acc: 0.8192\n",
      "Epoch 324/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.8598 - acc: 0.8245\n",
      "Epoch 325/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.7092 - acc: 0.8489\n",
      "Epoch 326/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.6914 - acc: 0.8625\n",
      "Epoch 327/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 3.6696 - acc: 0.8769\n",
      "Epoch 328/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.7047 - acc: 0.8772\n",
      "Epoch 329/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.6797 - acc: 0.8736\n",
      "Epoch 330/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.6951 - acc: 0.8645\n",
      "Epoch 331/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.6955 - acc: 0.8607\n",
      "Epoch 332/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.6569 - acc: 0.8882\n",
      "Epoch 333/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.7111 - acc: 0.8715\n",
      "Epoch 334/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.6783 - acc: 0.8799\n",
      "Epoch 335/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.6802 - acc: 0.8766\n",
      "Epoch 336/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.6738 - acc: 0.8779\n",
      "Epoch 337/1000\n",
      "65680/65680 [==============================] - 1s 9us/step - loss: 3.6867 - acc: 0.8604\n",
      "Epoch 338/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 3.7378 - acc: 0.8617\n",
      "Epoch 339/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 3.6901 - acc: 0.8746\n",
      "Epoch 340/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 3.7395 - acc: 0.8490\n",
      "Epoch 341/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.6591 - acc: 0.8653\n",
      "Epoch 342/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.6391 - acc: 0.8744\n",
      "Epoch 343/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.6424 - acc: 0.8617\n",
      "Epoch 344/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.6908 - acc: 0.8779\n",
      "Epoch 345/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.6583 - acc: 0.8670\n",
      "Epoch 346/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.6642 - acc: 0.8524\n",
      "Epoch 347/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.6847 - acc: 0.8757\n",
      "Epoch 348/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.6258 - acc: 0.8754\n",
      "Epoch 349/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.7046 - acc: 0.8417\n",
      "Epoch 350/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.6625 - acc: 0.8642\n",
      "Epoch 351/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.6727 - acc: 0.8505\n",
      "Epoch 352/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.6530 - acc: 0.8521\n",
      "Epoch 353/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 3.6916 - acc: 0.8714\n",
      "Epoch 354/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.6648 - acc: 0.8678\n",
      "Epoch 355/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.6909 - acc: 0.8559\n",
      "Epoch 356/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.6262 - acc: 0.8598\n",
      "Epoch 357/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 3.7040 - acc: 0.8602\n",
      "Epoch 358/1000\n",
      "65680/65680 [==============================] - 0s 8us/step - loss: 3.6304 - acc: 0.8635\n",
      "Epoch 359/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 3.7137 - acc: 0.8611\n",
      "Epoch 360/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 7.6902 - acc: 0.7958\n",
      "Epoch 361/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 6.1552 - acc: 0.8062\n",
      "Epoch 362/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 6.1968 - acc: 0.8058\n",
      "Epoch 363/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 5.9641 - acc: 0.7953\n",
      "Epoch 364/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 5.1450 - acc: 0.8088\n",
      "Epoch 365/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.5598 - acc: 0.7990\n",
      "Epoch 366/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.3838 - acc: 0.7900\n",
      "Epoch 367/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 4.0975 - acc: 0.8060\n",
      "Epoch 368/1000\n",
      "65680/65680 [==============================] - 1s 9us/step - loss: 4.3878 - acc: 0.8250\n",
      "Epoch 369/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.0924 - acc: 0.7842\n",
      "Epoch 370/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.2429 - acc: 0.7985\n",
      "Epoch 371/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.3816 - acc: 0.7819\n",
      "Epoch 372/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.0384 - acc: 0.7890\n",
      "Epoch 373/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.8619 - acc: 0.7988\n",
      "Epoch 374/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.9515 - acc: 0.8249\n",
      "Epoch 375/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.9974 - acc: 0.7839\n",
      "Epoch 376/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 3.7215 - acc: 0.8151\n",
      "Epoch 377/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 3.7019 - acc: 0.8595\n",
      "Epoch 378/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 3.7052 - acc: 0.8345\n",
      "Epoch 379/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.8355 - acc: 0.8262\n",
      "Epoch 380/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.9117 - acc: 0.8012\n",
      "Epoch 381/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.7998 - acc: 0.8244\n",
      "Epoch 382/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.7831 - acc: 0.8247\n",
      "Epoch 383/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.6817 - acc: 0.8312\n",
      "Epoch 384/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 3.6820 - acc: 0.8493\n",
      "Epoch 385/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 4.2686 - acc: 0.7986\n",
      "Epoch 386/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 5.0214 - acc: 0.7942\n",
      "Epoch 387/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 4.9089 - acc: 0.8054\n",
      "Epoch 388/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 4.3915 - acc: 0.7800\n",
      "Epoch 389/1000\n",
      "65680/65680 [==============================] - 1s 10us/step - loss: 4.2898 - acc: 0.8189\n",
      "Epoch 390/1000\n",
      "65680/65680 [==============================] - 1s 10us/step - loss: 4.3978 - acc: 0.8074\n",
      "Epoch 391/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 4.1235 - acc: 0.8089\n",
      "Epoch 392/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 3.9735 - acc: 0.8057\n",
      "Epoch 393/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 3.8181 - acc: 0.8244\n",
      "Epoch 394/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.7120 - acc: 0.8571\n",
      "Epoch 395/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.6986 - acc: 0.8456\n",
      "Epoch 396/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.7681 - acc: 0.8576\n",
      "Epoch 397/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.7457 - acc: 0.8682\n",
      "Epoch 398/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.6757 - acc: 0.8322\n",
      "Epoch 399/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.6119 - acc: 0.8479\n",
      "Epoch 400/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 3.7384 - acc: 0.8747\n",
      "Epoch 401/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 3.7110 - acc: 0.8707\n",
      "Epoch 402/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.6229 - acc: 0.8725\n",
      "Epoch 403/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.6353 - acc: 0.8593\n",
      "Epoch 404/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.6269 - acc: 0.8788\n",
      "Epoch 405/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.6233 - acc: 0.8661\n",
      "Epoch 406/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.8912 - acc: 0.8380\n",
      "Epoch 407/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.6704 - acc: 0.8108\n",
      "Epoch 408/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 5.2166 - acc: 0.8107\n",
      "Epoch 409/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.8913 - acc: 0.8085\n",
      "Epoch 410/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.2217 - acc: 0.7936\n",
      "Epoch 411/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.4048 - acc: 0.7903\n",
      "Epoch 412/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.8141 - acc: 0.7753\n",
      "Epoch 413/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.1165 - acc: 0.8149\n",
      "Epoch 414/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.3818 - acc: 0.8239\n",
      "Epoch 415/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.7780 - acc: 0.8054\n",
      "Epoch 416/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.0808 - acc: 0.8079\n",
      "Epoch 417/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.2435 - acc: 0.7951\n",
      "Epoch 418/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.9796 - acc: 0.8016\n",
      "Epoch 419/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 3.7531 - acc: 0.8010\n",
      "Epoch 420/1000\n",
      "65680/65680 [==============================] - 0s 8us/step - loss: 3.6961 - acc: 0.8256\n",
      "Epoch 421/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 3.6223 - acc: 0.8508\n",
      "Epoch 422/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.6326 - acc: 0.8519\n",
      "Epoch 423/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.6158 - acc: 0.8787\n",
      "Epoch 424/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.6727 - acc: 0.8644\n",
      "Epoch 425/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.7151 - acc: 0.8587\n",
      "Epoch 426/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.7137 - acc: 0.8370\n",
      "Epoch 427/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.7100 - acc: 0.8532\n",
      "Epoch 428/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 3.7287 - acc: 0.8574\n",
      "Epoch 429/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.6230 - acc: 0.8708\n",
      "Epoch 430/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.5703 - acc: 0.8781\n",
      "Epoch 431/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.5678 - acc: 0.8724\n",
      "Epoch 432/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.6273 - acc: 0.8699\n",
      "Epoch 433/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.6360 - acc: 0.8706\n",
      "Epoch 434/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.5678 - acc: 0.8541\n",
      "Epoch 435/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.5589 - acc: 0.8397\n",
      "Epoch 436/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 3.6148 - acc: 0.8570\n",
      "Epoch 437/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.5976 - acc: 0.8702\n",
      "Epoch 438/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.5770 - acc: 0.8582\n",
      "Epoch 439/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.5888 - acc: 0.8640\n",
      "Epoch 440/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.5722 - acc: 0.8606\n",
      "Epoch 441/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.6195 - acc: 0.8477\n",
      "Epoch 442/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.6237 - acc: 0.8447\n",
      "Epoch 443/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.5780 - acc: 0.8541\n",
      "Epoch 444/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.5916 - acc: 0.8714\n",
      "Epoch 445/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.5729 - acc: 0.8650\n",
      "Epoch 446/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 3.5762 - acc: 0.8862\n",
      "Epoch 447/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 3.5464 - acc: 0.8603\n",
      "Epoch 448/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.6178 - acc: 0.8642\n",
      "Epoch 449/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.6520 - acc: 0.8525\n",
      "Epoch 450/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.6044 - acc: 0.8501\n",
      "Epoch 451/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.5578 - acc: 0.8579\n",
      "Epoch 452/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.6583 - acc: 0.8336\n",
      "Epoch 453/1000\n",
      "65680/65680 [==============================] - 1s 9us/step - loss: 3.5599 - acc: 0.8453\n",
      "Epoch 454/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 3.5752 - acc: 0.8527\n",
      "Epoch 455/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 3.5644 - acc: 0.8768\n",
      "Epoch 456/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 3.5811 - acc: 0.8516\n",
      "Epoch 457/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.5678 - acc: 0.8513\n",
      "Epoch 458/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.6737 - acc: 0.8579\n",
      "Epoch 459/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.5542 - acc: 0.8619\n",
      "Epoch 460/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.5689 - acc: 0.8748\n",
      "Epoch 461/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 3.5505 - acc: 0.8530\n",
      "Epoch 462/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.5968 - acc: 0.8459\n",
      "Epoch 463/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.5572 - acc: 0.8522\n",
      "Epoch 464/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.5699 - acc: 0.8569\n",
      "Epoch 465/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.6010 - acc: 0.8669\n",
      "Epoch 466/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.5480 - acc: 0.8639\n",
      "Epoch 467/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.5614 - acc: 0.8455\n",
      "Epoch 468/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.5645 - acc: 0.8497\n",
      "Epoch 469/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.6735 - acc: 0.8354\n",
      "Epoch 470/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 5.8237 - acc: 0.8036\n",
      "Epoch 471/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 7.6547 - acc: 0.7872\n",
      "Epoch 472/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 6.3332 - acc: 0.7887\n",
      "Epoch 473/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 5.6653 - acc: 0.8023\n",
      "Epoch 474/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 5.1837 - acc: 0.7965\n",
      "Epoch 475/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.2807 - acc: 0.7935\n",
      "Epoch 476/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.3618 - acc: 0.8109\n",
      "Epoch 477/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.2391 - acc: 0.8036\n",
      "Epoch 478/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.1745 - acc: 0.7997\n",
      "Epoch 479/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 4.0701 - acc: 0.8119\n",
      "Epoch 480/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 4.7605 - acc: 0.8075\n",
      "Epoch 481/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.1107 - acc: 0.8017\n",
      "Epoch 482/1000\n",
      "65680/65680 [==============================] - 1s 9us/step - loss: 4.4403 - acc: 0.8099\n",
      "Epoch 483/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 4.4978 - acc: 0.8007\n",
      "Epoch 484/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 4.1306 - acc: 0.7990\n",
      "Epoch 485/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 3.8523 - acc: 0.8166\n",
      "Epoch 486/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 3.7669 - acc: 0.7935\n",
      "Epoch 487/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 3.6816 - acc: 0.8345\n",
      "Epoch 488/1000\n",
      "65680/65680 [==============================] - 1s 9us/step - loss: 3.7133 - acc: 0.8400\n",
      "Epoch 489/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 4.0213 - acc: 0.7958\n",
      "Epoch 490/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.8393 - acc: 0.8095\n",
      "Epoch 491/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.9661 - acc: 0.8014\n",
      "Epoch 492/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.1687 - acc: 0.8023\n",
      "Epoch 493/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.2073 - acc: 0.8107\n",
      "Epoch 494/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 4.5513 - acc: 0.7982\n",
      "Epoch 495/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.4432 - acc: 0.7878\n",
      "Epoch 496/1000\n",
      "65680/65680 [==============================] - 1s 9us/step - loss: 4.1759 - acc: 0.7844\n",
      "Epoch 497/1000\n",
      "65680/65680 [==============================] - 1s 9us/step - loss: 4.1481 - acc: 0.8038\n",
      "Epoch 498/1000\n",
      "65680/65680 [==============================] - 1s 9us/step - loss: 3.7968 - acc: 0.8244\n",
      "Epoch 499/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 3.7300 - acc: 0.8343\n",
      "Epoch 500/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 3.6403 - acc: 0.8346\n",
      "Epoch 501/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.1562 - acc: 0.8368\n",
      "Epoch 502/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 4.2166 - acc: 0.7725\n",
      "Epoch 503/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.7494 - acc: 0.8216\n",
      "Epoch 504/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 3.6426 - acc: 0.8571\n",
      "Epoch 505/1000\n",
      "65680/65680 [==============================] - 0s 8us/step - loss: 3.7690 - acc: 0.8149\n",
      "Epoch 506/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 4.2009 - acc: 0.7946\n",
      "Epoch 507/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 4.4817 - acc: 0.8009\n",
      "Epoch 508/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 4.2992 - acc: 0.8140\n",
      "Epoch 509/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 4.0452 - acc: 0.7970\n",
      "Epoch 510/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 3.8217 - acc: 0.8309\n",
      "Epoch 511/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 3.7209 - acc: 0.8029\n",
      "Epoch 512/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 3.7207 - acc: 0.7986\n",
      "Epoch 513/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 3.6055 - acc: 0.8296\n",
      "Epoch 514/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.5499 - acc: 0.8415\n",
      "Epoch 515/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.5374 - acc: 0.8560\n",
      "Epoch 516/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.5480 - acc: 0.8598\n",
      "Epoch 517/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.5267 - acc: 0.8483\n",
      "Epoch 518/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.5507 - acc: 0.8565\n",
      "Epoch 519/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.5738 - acc: 0.8466\n",
      "Epoch 520/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.5741 - acc: 0.8612\n",
      "Epoch 521/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.5453 - acc: 0.8742\n",
      "Epoch 522/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.5552 - acc: 0.8304\n",
      "Epoch 523/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.5251 - acc: 0.8808\n",
      "Epoch 524/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 3.6318 - acc: 0.8483\n",
      "Epoch 525/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 3.5223 - acc: 0.8489\n",
      "Epoch 526/1000\n",
      "65680/65680 [==============================] - 1s 9us/step - loss: 3.6352 - acc: 0.8656\n",
      "Epoch 527/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.6049 - acc: 0.8632\n",
      "Epoch 528/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 3.5166 - acc: 0.8792\n",
      "Epoch 529/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 3.5077 - acc: 0.8769\n",
      "Epoch 530/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 3.4850 - acc: 0.8724\n",
      "Epoch 531/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 3.5193 - acc: 0.8651\n",
      "Epoch 532/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.5623 - acc: 0.8654\n",
      "Epoch 533/1000\n",
      "65680/65680 [==============================] - 1s 9us/step - loss: 3.5069 - acc: 0.8638\n",
      "Epoch 534/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.5265 - acc: 0.8674\n",
      "Epoch 535/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 3.4869 - acc: 0.8641\n",
      "Epoch 536/1000\n",
      "65680/65680 [==============================] - 1s 9us/step - loss: 3.4927 - acc: 0.8516\n",
      "Epoch 537/1000\n",
      "65680/65680 [==============================] - 1s 9us/step - loss: 3.5087 - acc: 0.8752\n",
      "Epoch 538/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.5188 - acc: 0.8606\n",
      "Epoch 539/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 3.5106 - acc: 0.8667\n",
      "Epoch 540/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 3.4718 - acc: 0.8466\n",
      "Epoch 541/1000\n",
      "65680/65680 [==============================] - 0s 6us/step - loss: 3.5185 - acc: 0.8711\n",
      "Epoch 542/1000\n",
      "65680/65680 [==============================] - 1s 9us/step - loss: 3.5041 - acc: 0.8844\n",
      "Epoch 543/1000\n",
      "65680/65680 [==============================] - 1s 9us/step - loss: 3.5516 - acc: 0.8372\n",
      "Epoch 544/1000\n",
      "65680/65680 [==============================] - 1s 9us/step - loss: 3.4706 - acc: 0.8518\n",
      "Epoch 545/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.5046 - acc: 0.8708\n",
      "Epoch 546/1000\n",
      "65680/65680 [==============================] - 0s 8us/step - loss: 3.5222 - acc: 0.8733\n",
      "Epoch 547/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4570 - acc: 0.8734\n",
      "Epoch 548/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.5008 - acc: 0.8453\n",
      "Epoch 549/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 3.6589 - acc: 0.8527\n",
      "Epoch 550/1000\n",
      "65680/65680 [==============================] - 0s 4us/step - loss: 6.2130 - acc: 0.7970\n",
      "Epoch 551/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 6.2664 - acc: 0.7818\n",
      "Epoch 552/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 5.7075 - acc: 0.8053\n",
      "Epoch 553/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.6708 - acc: 0.8084\n",
      "Epoch 554/1000\n",
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.7624 - acc: 0.7934\n",
      "Epoch 555/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65680/65680 [==============================] - 0s 5us/step - loss: 4.9787 - acc: 0.7931\n",
      "Epoch 556/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 4.1452 - acc: 0.7934\n",
      "Epoch 557/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.9830 - acc: 0.8148\n",
      "Epoch 558/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.8741 - acc: 0.8131\n",
      "Epoch 559/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.8658 - acc: 0.8311\n",
      "Epoch 560/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.3538 - acc: 0.7891\n",
      "Epoch 561/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.9166 - acc: 0.8076\n",
      "Epoch 562/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.7263 - acc: 0.7983\n",
      "Epoch 563/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.7876 - acc: 0.8152\n",
      "Epoch 564/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.8190 - acc: 0.8222\n",
      "Epoch 565/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.1922 - acc: 0.7971\n",
      "Epoch 566/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.0675 - acc: 0.7895\n",
      "Epoch 567/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.1358 - acc: 0.8054\n",
      "Epoch 568/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.1464 - acc: 0.8049\n",
      "Epoch 569/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.8514 - acc: 0.8214\n",
      "Epoch 570/1000\n",
      "65680/65680 [==============================] - 0s 8us/step - loss: 3.9703 - acc: 0.8229\n",
      "Epoch 571/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.0523 - acc: 0.7932\n",
      "Epoch 572/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.4024 - acc: 0.7825\n",
      "Epoch 573/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.9789 - acc: 0.7937\n",
      "Epoch 574/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.6947 - acc: 0.7984\n",
      "Epoch 575/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.6081 - acc: 0.8480\n",
      "Epoch 576/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.6469 - acc: 0.8121\n",
      "Epoch 577/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.5609 - acc: 0.8225\n",
      "Epoch 578/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.7996 - acc: 0.8067\n",
      "Epoch 579/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.6807 - acc: 0.8115\n",
      "Epoch 580/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.6878 - acc: 0.8144\n",
      "Epoch 581/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.8237 - acc: 0.8167\n",
      "Epoch 582/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.0657 - acc: 0.8013\n",
      "Epoch 583/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.9015 - acc: 0.8110\n",
      "Epoch 584/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.6667 - acc: 0.8340\n",
      "Epoch 585/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.6684 - acc: 0.8160\n",
      "Epoch 586/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.6546 - acc: 0.8346\n",
      "Epoch 587/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.7434 - acc: 0.8175\n",
      "Epoch 588/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.6280 - acc: 0.8217\n",
      "Epoch 589/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.5450 - acc: 0.8214\n",
      "Epoch 590/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4854 - acc: 0.8505\n",
      "Epoch 591/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4793 - acc: 0.8707\n",
      "Epoch 592/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4747 - acc: 0.8647\n",
      "Epoch 593/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4552 - acc: 0.8714\n",
      "Epoch 594/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4752 - acc: 0.8637\n",
      "Epoch 595/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4574 - acc: 0.8751\n",
      "Epoch 596/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4439 - acc: 0.8564\n",
      "Epoch 597/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4470 - acc: 0.8651\n",
      "Epoch 598/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4492 - acc: 0.8557\n",
      "Epoch 599/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4581 - acc: 0.8657\n",
      "Epoch 600/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4645 - acc: 0.8593\n",
      "Epoch 601/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4472 - acc: 0.8617\n",
      "Epoch 602/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.5081 - acc: 0.8666\n",
      "Epoch 603/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4949 - acc: 0.8551\n",
      "Epoch 604/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4907 - acc: 0.8558\n",
      "Epoch 605/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4493 - acc: 0.8849\n",
      "Epoch 606/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4370 - acc: 0.8734\n",
      "Epoch 607/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4314 - acc: 0.8759\n",
      "Epoch 608/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4423 - acc: 0.8448\n",
      "Epoch 609/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4559 - acc: 0.8608\n",
      "Epoch 610/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4675 - acc: 0.8612\n",
      "Epoch 611/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4663 - acc: 0.8530\n",
      "Epoch 612/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4334 - acc: 0.8626\n",
      "Epoch 613/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4302 - acc: 0.8524\n",
      "Epoch 614/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4634 - acc: 0.8624\n",
      "Epoch 615/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4550 - acc: 0.8638\n",
      "Epoch 616/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4253 - acc: 0.8707\n",
      "Epoch 617/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4710 - acc: 0.8375\n",
      "Epoch 618/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4159 - acc: 0.8718\n",
      "Epoch 619/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4570 - acc: 0.8621\n",
      "Epoch 620/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4751 - acc: 0.8472\n",
      "Epoch 621/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4077 - acc: 0.8530\n",
      "Epoch 622/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4565 - acc: 0.8404\n",
      "Epoch 623/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.5396 - acc: 0.8608\n",
      "Epoch 624/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.5063 - acc: 0.8302\n",
      "Epoch 625/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4221 - acc: 0.8368\n",
      "Epoch 626/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.9649 - acc: 0.8542\n",
      "Epoch 627/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 8.1657 - acc: 0.7793\n",
      "Epoch 628/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 7.0505 - acc: 0.7971\n",
      "Epoch 629/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 5.0156 - acc: 0.7850\n",
      "Epoch 630/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 5.4741 - acc: 0.7979\n",
      "Epoch 631/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.4945 - acc: 0.8149\n",
      "Epoch 632/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.0433 - acc: 0.7920\n",
      "Epoch 633/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.5647 - acc: 0.8137\n",
      "Epoch 634/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.9355 - acc: 0.7967\n",
      "Epoch 635/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.1731 - acc: 0.7953\n",
      "Epoch 636/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.9928 - acc: 0.8084\n",
      "Epoch 637/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.5985 - acc: 0.8317\n",
      "Epoch 638/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.5011 - acc: 0.8642\n",
      "Epoch 639/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4619 - acc: 0.8603\n",
      "Epoch 640/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4367 - acc: 0.8674\n",
      "Epoch 641/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4239 - acc: 0.8717\n",
      "Epoch 642/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4267 - acc: 0.8721\n",
      "Epoch 643/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4178 - acc: 0.8779\n",
      "Epoch 644/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4127 - acc: 0.8745\n",
      "Epoch 645/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.5030 - acc: 0.8745\n",
      "Epoch 646/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4216 - acc: 0.8619\n",
      "Epoch 647/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3959 - acc: 0.8636\n",
      "Epoch 648/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4262 - acc: 0.8559\n",
      "Epoch 649/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3828 - acc: 0.8811\n",
      "Epoch 650/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3959 - acc: 0.8809\n",
      "Epoch 651/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4216 - acc: 0.8778\n",
      "Epoch 652/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3824 - acc: 0.8715\n",
      "Epoch 653/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3987 - acc: 0.8704\n",
      "Epoch 654/1000\n",
      "65680/65680 [==============================] - 0s 8us/step - loss: 3.3947 - acc: 0.8551\n",
      "Epoch 655/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3858 - acc: 0.8737\n",
      "Epoch 656/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3953 - acc: 0.8776\n",
      "Epoch 657/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3742 - acc: 0.8727\n",
      "Epoch 658/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3924 - acc: 0.8827\n",
      "Epoch 659/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3867 - acc: 0.8667\n",
      "Epoch 660/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4173 - acc: 0.8656\n",
      "Epoch 661/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4037 - acc: 0.8758\n",
      "Epoch 662/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3885 - acc: 0.8770\n",
      "Epoch 663/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4317 - acc: 0.8608\n",
      "Epoch 664/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4325 - acc: 0.8761\n",
      "Epoch 665/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3733 - acc: 0.8727\n",
      "Epoch 666/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4169 - acc: 0.8672\n",
      "Epoch 667/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4163 - acc: 0.8618\n",
      "Epoch 668/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4012 - acc: 0.8752\n",
      "Epoch 669/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3787 - acc: 0.8595\n",
      "Epoch 670/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3875 - acc: 0.8847\n",
      "Epoch 671/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4149 - acc: 0.8626\n",
      "Epoch 672/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4474 - acc: 0.8466\n",
      "Epoch 673/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3997 - acc: 0.8471\n",
      "Epoch 674/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3923 - acc: 0.8641\n",
      "Epoch 675/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3721 - acc: 0.8643\n",
      "Epoch 676/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4026 - acc: 0.8530\n",
      "Epoch 677/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3788 - acc: 0.8589\n",
      "Epoch 678/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4457 - acc: 0.8648\n",
      "Epoch 679/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4386 - acc: 0.8594\n",
      "Epoch 680/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3773 - acc: 0.8531\n",
      "Epoch 681/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3907 - acc: 0.8520\n",
      "Epoch 682/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3899 - acc: 0.8551\n",
      "Epoch 683/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4122 - acc: 0.8442\n",
      "Epoch 684/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3828 - acc: 0.8431\n",
      "Epoch 685/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3499 - acc: 0.8391\n",
      "Epoch 686/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4284 - acc: 0.8495\n",
      "Epoch 687/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4767 - acc: 0.8359\n",
      "Epoch 688/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3649 - acc: 0.8375\n",
      "Epoch 689/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4107 - acc: 0.8510\n",
      "Epoch 690/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4124 - acc: 0.8401\n",
      "Epoch 691/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.7379 - acc: 0.8325\n",
      "Epoch 692/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 7.6710 - acc: 0.8030\n",
      "Epoch 693/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 7.8045 - acc: 0.8005\n",
      "Epoch 694/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 6.5879 - acc: 0.7888\n",
      "Epoch 695/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.9932 - acc: 0.7927\n",
      "Epoch 696/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.8820 - acc: 0.7946\n",
      "Epoch 697/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.6071 - acc: 0.7573\n",
      "Epoch 698/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.9374 - acc: 0.8126\n",
      "Epoch 699/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.8275 - acc: 0.7941\n",
      "Epoch 700/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.8767 - acc: 0.8097\n",
      "Epoch 701/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.6894 - acc: 0.7994\n",
      "Epoch 702/1000\n",
      "65680/65680 [==============================] - 1s 9us/step - loss: 4.2808 - acc: 0.8141\n",
      "Epoch 703/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.3026 - acc: 0.7812\n",
      "Epoch 704/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.1784 - acc: 0.8024\n",
      "Epoch 705/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.8528 - acc: 0.8081\n",
      "Epoch 706/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.9937 - acc: 0.7987\n",
      "Epoch 707/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.8870 - acc: 0.8137\n",
      "Epoch 708/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.7668 - acc: 0.8029\n",
      "Epoch 709/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.5216 - acc: 0.8218\n",
      "Epoch 710/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.5111 - acc: 0.8395\n",
      "Epoch 711/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4973 - acc: 0.8471\n",
      "Epoch 712/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 3.4584 - acc: 0.8219\n",
      "Epoch 713/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.5017 - acc: 0.8397\n",
      "Epoch 714/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4926 - acc: 0.8116\n",
      "Epoch 715/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.5368 - acc: 0.8242\n",
      "Epoch 716/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.5846 - acc: 0.8425\n",
      "Epoch 717/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.6611 - acc: 0.8294\n",
      "Epoch 718/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.6604 - acc: 0.7821\n",
      "Epoch 719/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.7205 - acc: 0.8198\n",
      "Epoch 720/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.2035 - acc: 0.7773\n",
      "Epoch 721/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.9280 - acc: 0.8184\n",
      "Epoch 722/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.0449 - acc: 0.7836\n",
      "Epoch 723/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.2065 - acc: 0.7997\n",
      "Epoch 724/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.7941 - acc: 0.7916\n",
      "Epoch 725/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.6855 - acc: 0.7865\n",
      "Epoch 726/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.5451 - acc: 0.8291\n",
      "Epoch 727/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.5519 - acc: 0.8488\n",
      "Epoch 728/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.5978 - acc: 0.8277\n",
      "Epoch 729/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.0177 - acc: 0.7945\n",
      "Epoch 730/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.9861 - acc: 0.7937\n",
      "Epoch 731/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.6028 - acc: 0.8145\n",
      "Epoch 732/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.5163 - acc: 0.8265\n",
      "Epoch 733/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.5122 - acc: 0.8251\n",
      "Epoch 734/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.5676 - acc: 0.8292\n",
      "Epoch 735/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4139 - acc: 0.8266\n",
      "Epoch 736/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3941 - acc: 0.8522\n",
      "Epoch 737/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3549 - acc: 0.8633\n",
      "Epoch 738/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3612 - acc: 0.8470\n",
      "Epoch 739/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3296 - acc: 0.8678\n",
      "Epoch 740/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3690 - acc: 0.8682\n",
      "Epoch 741/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3434 - acc: 0.8750\n",
      "Epoch 742/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3575 - acc: 0.8660\n",
      "Epoch 743/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3549 - acc: 0.8522\n",
      "Epoch 744/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3193 - acc: 0.8516\n",
      "Epoch 745/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3473 - acc: 0.8605\n",
      "Epoch 746/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4269 - acc: 0.8498\n",
      "Epoch 747/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3372 - acc: 0.8560\n",
      "Epoch 748/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3256 - acc: 0.8713\n",
      "Epoch 749/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3484 - acc: 0.8734\n",
      "Epoch 750/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3479 - acc: 0.8494\n",
      "Epoch 751/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3181 - acc: 0.8731\n",
      "Epoch 752/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3698 - acc: 0.8603\n",
      "Epoch 753/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3392 - acc: 0.8627\n",
      "Epoch 754/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3742 - acc: 0.8748\n",
      "Epoch 755/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3186 - acc: 0.8655\n",
      "Epoch 756/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3435 - acc: 0.8493\n",
      "Epoch 757/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3518 - acc: 0.8660\n",
      "Epoch 758/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3332 - acc: 0.8582\n",
      "Epoch 759/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3477 - acc: 0.8435\n",
      "Epoch 760/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3589 - acc: 0.8533\n",
      "Epoch 761/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4162 - acc: 0.8554\n",
      "Epoch 762/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3293 - acc: 0.8730\n",
      "Epoch 763/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.2872 - acc: 0.8411\n",
      "Epoch 764/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3171 - acc: 0.8532\n",
      "Epoch 765/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3343 - acc: 0.8629\n",
      "Epoch 766/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3675 - acc: 0.8703\n",
      "Epoch 767/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3032 - acc: 0.8466\n",
      "Epoch 768/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.2787 - acc: 0.8626\n",
      "Epoch 769/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3036 - acc: 0.8451\n",
      "Epoch 770/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3435 - acc: 0.8600\n",
      "Epoch 771/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.5753 - acc: 0.8276\n",
      "Epoch 772/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 6.1906 - acc: 0.7901\n",
      "Epoch 773/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 6.8264 - acc: 0.7796\n",
      "Epoch 774/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 5.6117 - acc: 0.7986\n",
      "Epoch 775/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.7920 - acc: 0.7955\n",
      "Epoch 776/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.1563 - acc: 0.7701\n",
      "Epoch 777/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 5.0978 - acc: 0.7836\n",
      "Epoch 778/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.9799 - acc: 0.8024\n",
      "Epoch 779/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.5641 - acc: 0.8251\n",
      "Epoch 780/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.5081 - acc: 0.8310\n",
      "Epoch 781/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.5055 - acc: 0.8137\n",
      "Epoch 782/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.5771 - acc: 0.8091\n",
      "Epoch 783/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.7061 - acc: 0.7971\n",
      "Epoch 784/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.3258 - acc: 0.7788\n",
      "Epoch 785/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.0192 - acc: 0.7909\n",
      "Epoch 786/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.1353 - acc: 0.8085\n",
      "Epoch 787/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.9360 - acc: 0.7898\n",
      "Epoch 788/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.7967 - acc: 0.7963\n",
      "Epoch 789/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.6849 - acc: 0.8082\n",
      "Epoch 790/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.1354 - acc: 0.7860\n",
      "Epoch 791/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.4999 - acc: 0.7996\n",
      "Epoch 792/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.8775 - acc: 0.7852\n",
      "Epoch 793/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4708 - acc: 0.8329\n",
      "Epoch 794/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4213 - acc: 0.8279\n",
      "Epoch 795/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3890 - acc: 0.8557\n",
      "Epoch 796/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4350 - acc: 0.8412\n",
      "Epoch 797/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4488 - acc: 0.8270\n",
      "Epoch 798/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3457 - acc: 0.8475\n",
      "Epoch 799/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4149 - acc: 0.8486\n",
      "Epoch 800/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4401 - acc: 0.8389\n",
      "Epoch 801/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3150 - acc: 0.8432\n",
      "Epoch 802/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3875 - acc: 0.8505\n",
      "Epoch 803/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4711 - acc: 0.8350\n",
      "Epoch 804/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.6040 - acc: 0.8112\n",
      "Epoch 805/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.7145 - acc: 0.8044\n",
      "Epoch 806/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.7426 - acc: 0.7934\n",
      "Epoch 807/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.3453 - acc: 0.8300\n",
      "Epoch 808/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 5.3734 - acc: 0.7904\n",
      "Epoch 809/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 5.4445 - acc: 0.7815\n",
      "Epoch 810/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.8152 - acc: 0.8087\n",
      "Epoch 811/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.0557 - acc: 0.7902\n",
      "Epoch 812/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.5598 - acc: 0.8002\n",
      "Epoch 813/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4171 - acc: 0.8228\n",
      "Epoch 814/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4479 - acc: 0.8602\n",
      "Epoch 815/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.6804 - acc: 0.7831\n",
      "Epoch 816/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4301 - acc: 0.8180\n",
      "Epoch 817/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3655 - acc: 0.8275\n",
      "Epoch 818/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3096 - acc: 0.8683\n",
      "Epoch 819/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3135 - acc: 0.8613\n",
      "Epoch 820/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.2988 - acc: 0.8617\n",
      "Epoch 821/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3050 - acc: 0.8778\n",
      "Epoch 822/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3136 - acc: 0.8438\n",
      "Epoch 823/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.2701 - acc: 0.8702\n",
      "Epoch 824/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3182 - acc: 0.8558\n",
      "Epoch 825/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3244 - acc: 0.8649\n",
      "Epoch 826/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.2884 - acc: 0.8411\n",
      "Epoch 827/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.2707 - acc: 0.8638\n",
      "Epoch 828/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.2589 - acc: 0.8729\n",
      "Epoch 829/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.2859 - acc: 0.8710\n",
      "Epoch 830/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.2915 - acc: 0.8683\n",
      "Epoch 831/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3155 - acc: 0.8631\n",
      "Epoch 832/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.2525 - acc: 0.8672\n",
      "Epoch 833/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.2602 - acc: 0.8517\n",
      "Epoch 834/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3016 - acc: 0.8665\n",
      "Epoch 835/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3039 - acc: 0.8381\n",
      "Epoch 836/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.2965 - acc: 0.8580\n",
      "Epoch 837/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4153 - acc: 0.8618\n",
      "Epoch 838/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.2639 - acc: 0.8663\n",
      "Epoch 839/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.2710 - acc: 0.8674\n",
      "Epoch 840/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.2658 - acc: 0.8666\n",
      "Epoch 841/1000\n",
      "65680/65680 [==============================] - 0s 8us/step - loss: 3.2903 - acc: 0.8639\n",
      "Epoch 842/1000\n",
      "65680/65680 [==============================] - 0s 8us/step - loss: 3.2732 - acc: 0.8528\n",
      "Epoch 843/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.2901 - acc: 0.8546\n",
      "Epoch 844/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.2985 - acc: 0.8571\n",
      "Epoch 845/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.2729 - acc: 0.8728\n",
      "Epoch 846/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.2747 - acc: 0.8604\n",
      "Epoch 847/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.2641 - acc: 0.8488\n",
      "Epoch 848/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3025 - acc: 0.8686\n",
      "Epoch 849/1000\n",
      "65680/65680 [==============================] - 0s 8us/step - loss: 3.3250 - acc: 0.8334\n",
      "Epoch 850/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.2413 - acc: 0.8427\n",
      "Epoch 851/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.2803 - acc: 0.8545\n",
      "Epoch 852/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.2549 - acc: 0.8722\n",
      "Epoch 853/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.2925 - acc: 0.8246\n",
      "Epoch 854/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.2687 - acc: 0.8442\n",
      "Epoch 855/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.2623 - acc: 0.8351\n",
      "Epoch 856/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.2996 - acc: 0.8309\n",
      "Epoch 857/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.2321 - acc: 0.8676\n",
      "Epoch 858/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.2337 - acc: 0.8424\n",
      "Epoch 859/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.2482 - acc: 0.8464\n",
      "Epoch 860/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.2925 - acc: 0.8727\n",
      "Epoch 861/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.2381 - acc: 0.8496\n",
      "Epoch 862/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.2594 - acc: 0.8549\n",
      "Epoch 863/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.2586 - acc: 0.8378\n",
      "Epoch 864/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.2690 - acc: 0.8462\n",
      "Epoch 865/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.2791 - acc: 0.8292\n",
      "Epoch 866/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3203 - acc: 0.8428\n",
      "Epoch 867/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.2807 - acc: 0.8298\n",
      "Epoch 868/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.2602 - acc: 0.8304\n",
      "Epoch 869/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.2924 - acc: 0.8379\n",
      "Epoch 870/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3120 - acc: 0.8373\n",
      "Epoch 871/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4297 - acc: 0.8372\n",
      "Epoch 872/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.2174 - acc: 0.8531\n",
      "Epoch 873/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.2212 - acc: 0.8479\n",
      "Epoch 874/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3396 - acc: 0.8476\n",
      "Epoch 875/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 7.2616 - acc: 0.7914\n",
      "Epoch 876/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 7.1585 - acc: 0.7794\n",
      "Epoch 877/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 6.7505 - acc: 0.7996\n",
      "Epoch 878/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 5.8728 - acc: 0.7860\n",
      "Epoch 879/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.6868 - acc: 0.8084\n",
      "Epoch 880/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.1599 - acc: 0.8188\n",
      "Epoch 881/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.9084 - acc: 0.8069\n",
      "Epoch 882/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.9189 - acc: 0.7751\n",
      "Epoch 883/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.8339 - acc: 0.8081\n",
      "Epoch 884/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.5974 - acc: 0.8371\n",
      "Epoch 885/1000\n",
      "65680/65680 [==============================] - 1s 9us/step - loss: 3.4338 - acc: 0.8273\n",
      "Epoch 886/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.0131 - acc: 0.8165\n",
      "Epoch 887/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.7598 - acc: 0.7891\n",
      "Epoch 888/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.8201 - acc: 0.7823\n",
      "Epoch 889/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.6144 - acc: 0.7834\n",
      "Epoch 890/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4184 - acc: 0.8115\n",
      "Epoch 891/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3756 - acc: 0.8473\n",
      "Epoch 892/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3677 - acc: 0.8575\n",
      "Epoch 893/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3768 - acc: 0.8417\n",
      "Epoch 894/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4346 - acc: 0.7828\n",
      "Epoch 895/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3192 - acc: 0.8320\n",
      "Epoch 896/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3468 - acc: 0.8480\n",
      "Epoch 897/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.6783 - acc: 0.8056\n",
      "Epoch 898/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.1143 - acc: 0.7840\n",
      "Epoch 899/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.9377 - acc: 0.7986\n",
      "Epoch 900/1000\n",
      "65680/65680 [==============================] - 0s 8us/step - loss: 3.6311 - acc: 0.8078\n",
      "Epoch 901/1000\n",
      "65680/65680 [==============================] - 0s 8us/step - loss: 3.4249 - acc: 0.8030\n",
      "Epoch 902/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4335 - acc: 0.8439\n",
      "Epoch 903/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3885 - acc: 0.8252\n",
      "Epoch 904/1000\n",
      "65680/65680 [==============================] - 0s 8us/step - loss: 3.2885 - acc: 0.8547\n",
      "Epoch 905/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4389 - acc: 0.8501\n",
      "Epoch 906/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.1597 - acc: 0.7969\n",
      "Epoch 907/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.3200 - acc: 0.7876\n",
      "Epoch 908/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.3552 - acc: 0.8016\n",
      "Epoch 909/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.7859 - acc: 0.7997\n",
      "Epoch 910/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.5692 - acc: 0.8142\n",
      "Epoch 911/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.7989 - acc: 0.8038\n",
      "Epoch 912/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.0255 - acc: 0.7945\n",
      "Epoch 913/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 3.6394 - acc: 0.7947\n",
      "Epoch 914/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.7005 - acc: 0.7969\n",
      "Epoch 915/1000\n",
      "65680/65680 [==============================] - 0s 8us/step - loss: 3.4717 - acc: 0.7960\n",
      "Epoch 916/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4114 - acc: 0.8098\n",
      "Epoch 917/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4401 - acc: 0.8142\n",
      "Epoch 918/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3588 - acc: 0.8364\n",
      "Epoch 919/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4143 - acc: 0.8094\n",
      "Epoch 920/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.5942 - acc: 0.8361\n",
      "Epoch 921/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.5418 - acc: 0.7894\n",
      "Epoch 922/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.5186 - acc: 0.8034\n",
      "Epoch 923/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.6967 - acc: 0.8105\n",
      "Epoch 924/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4905 - acc: 0.7929\n",
      "Epoch 925/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3881 - acc: 0.8230\n",
      "Epoch 926/1000\n",
      "65680/65680 [==============================] - 0s 8us/step - loss: 3.6633 - acc: 0.8151\n",
      "Epoch 927/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.1636 - acc: 0.8033\n",
      "Epoch 928/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.4319 - acc: 0.8126\n",
      "Epoch 929/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.9602 - acc: 0.8045\n",
      "Epoch 930/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.5365 - acc: 0.7995\n",
      "Epoch 931/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4433 - acc: 0.8239\n",
      "Epoch 932/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4052 - acc: 0.8035\n",
      "Epoch 933/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3250 - acc: 0.8093\n",
      "Epoch 934/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3358 - acc: 0.8412\n",
      "Epoch 935/1000\n",
      "65680/65680 [==============================] - 0s 8us/step - loss: 3.3366 - acc: 0.8272\n",
      "Epoch 936/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4833 - acc: 0.8268\n",
      "Epoch 937/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.6845 - acc: 0.8031\n",
      "Epoch 938/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.0097 - acc: 0.7812\n",
      "Epoch 939/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.9686 - acc: 0.7896\n",
      "Epoch 940/1000\n",
      "65680/65680 [==============================] - 0s 8us/step - loss: 3.7700 - acc: 0.7883\n",
      "Epoch 941/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.5157 - acc: 0.8138\n",
      "Epoch 942/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4783 - acc: 0.7892\n",
      "Epoch 943/1000\n",
      "65680/65680 [==============================] - 0s 8us/step - loss: 3.3873 - acc: 0.8329\n",
      "Epoch 944/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.2792 - acc: 0.8373\n",
      "Epoch 945/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.2751 - acc: 0.8449\n",
      "Epoch 946/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.2136 - acc: 0.8565\n",
      "Epoch 947/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3539 - acc: 0.8216\n",
      "Epoch 948/1000\n",
      "65680/65680 [==============================] - 0s 8us/step - loss: 3.2949 - acc: 0.8221\n",
      "Epoch 949/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3135 - acc: 0.8533\n",
      "Epoch 950/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.2983 - acc: 0.8460\n",
      "Epoch 951/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.5357 - acc: 0.8195\n",
      "Epoch 952/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.5952 - acc: 0.8027\n",
      "Epoch 953/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.6087 - acc: 0.8067\n",
      "Epoch 954/1000\n",
      "65680/65680 [==============================] - 0s 8us/step - loss: 4.1721 - acc: 0.7830\n",
      "Epoch 955/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.3820 - acc: 0.7842\n",
      "Epoch 956/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 5.1981 - acc: 0.8169\n",
      "Epoch 957/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 4.1067 - acc: 0.7953\n",
      "Epoch 958/1000\n",
      "65680/65680 [==============================] - 0s 8us/step - loss: 3.4267 - acc: 0.8097\n",
      "Epoch 959/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3665 - acc: 0.8223\n",
      "Epoch 960/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3121 - acc: 0.8253\n",
      "Epoch 961/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.5276 - acc: 0.8053\n",
      "Epoch 962/1000\n",
      "65680/65680 [==============================] - 0s 8us/step - loss: 3.6587 - acc: 0.8113\n",
      "Epoch 963/1000\n",
      "65680/65680 [==============================] - 0s 8us/step - loss: 3.6828 - acc: 0.8073\n",
      "Epoch 964/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.8394 - acc: 0.8009\n",
      "Epoch 965/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.6243 - acc: 0.7831\n",
      "Epoch 966/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4608 - acc: 0.8245\n",
      "Epoch 967/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4095 - acc: 0.8268\n",
      "Epoch 968/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 3.7342 - acc: 0.8042\n",
      "Epoch 969/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.9983 - acc: 0.7688\n",
      "Epoch 970/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.7571 - acc: 0.8324\n",
      "Epoch 971/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.6175 - acc: 0.7840\n",
      "Epoch 972/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4020 - acc: 0.8010\n",
      "Epoch 973/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.5241 - acc: 0.7971\n",
      "Epoch 974/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.7806 - acc: 0.7636\n",
      "Epoch 975/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.9785 - acc: 0.7953\n",
      "Epoch 976/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.6444 - acc: 0.8144\n",
      "Epoch 977/1000\n",
      "65680/65680 [==============================] - 0s 8us/step - loss: 3.6919 - acc: 0.7881\n",
      "Epoch 978/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 3.6308 - acc: 0.7934\n",
      "Epoch 979/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.8836 - acc: 0.7905\n",
      "Epoch 980/1000\n",
      "65680/65680 [==============================] - 0s 8us/step - loss: 3.9654 - acc: 0.7727\n",
      "Epoch 981/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.6114 - acc: 0.7954\n",
      "Epoch 982/1000\n",
      "65680/65680 [==============================] - 0s 8us/step - loss: 3.3807 - acc: 0.8041\n",
      "Epoch 983/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.6515 - acc: 0.8133\n",
      "Epoch 984/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 3.8677 - acc: 0.7895\n",
      "Epoch 985/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.6044 - acc: 0.7780\n",
      "Epoch 986/1000\n",
      "65680/65680 [==============================] - 0s 8us/step - loss: 3.5247 - acc: 0.8147\n",
      "Epoch 987/1000\n",
      "65680/65680 [==============================] - 0s 8us/step - loss: 3.5280 - acc: 0.7918\n",
      "Epoch 988/1000\n",
      "65680/65680 [==============================] - 0s 8us/step - loss: 3.3703 - acc: 0.8022\n",
      "Epoch 989/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.4153 - acc: 0.7820\n",
      "Epoch 990/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.5035 - acc: 0.8038\n",
      "Epoch 991/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.6762 - acc: 0.8129\n",
      "Epoch 992/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.5547 - acc: 0.8103\n",
      "Epoch 993/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.9882 - acc: 0.8039\n",
      "Epoch 994/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.8196 - acc: 0.7802\n",
      "Epoch 995/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.8735 - acc: 0.8224\n",
      "Epoch 996/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.3908 - acc: 0.7921\n",
      "Epoch 997/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.2600 - acc: 0.8427\n",
      "Epoch 998/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.2213 - acc: 0.8583\n",
      "Epoch 999/1000\n",
      "65680/65680 [==============================] - 0s 7us/step - loss: 3.2171 - acc: 0.8604\n",
      "Epoch 1000/1000\n",
      "65680/65680 [==============================] - 1s 8us/step - loss: 3.1768 - acc: 0.8628\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=2000, epochs=1000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot accuracy history\n",
    "# summarize history for accuracy \n",
    "plt.plot(history.history['acc'])\n",
    "#plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "#acc_png = './training history/' + file_name + '_accuracy.png'\n",
    "#plt.savefig(acc_png)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65680, 9, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 76.53510284 298.64001465  42.41149902]\n",
      " [ 76.16439819 287.62799072  43.0707016 ]\n",
      " [ 75.80950165 277.11898804  43.44910049]\n",
      " [ 75.70410156 265.83700562  43.76070023]\n",
      " [ 75.36289978 255.05999756  43.82559967]\n",
      " [ 75.04460144 245.96299744  43.2195015 ]\n",
      " [ 74.72219849 234.96800232  43.02759933]\n",
      " [ 74.42099762 225.53999329  42.43379974]\n",
      " [ 73.9108963  216.45399475  41.65539932]]\n",
      "[[ 73.6289978  206.82899475  40.43310165]\n",
      " [ 73.14569855 196.58900452  39.68360138]\n",
      " [ 72.68139648 186.82699585  38.35089874]\n",
      " [ 72.03569794 179.14700317  36.31200027]\n",
      " [ 71.80599976 167.70300293  35.07360077]\n",
      " [ 71.20140076 159.83999634  32.99610138]\n",
      " [ 70.80509949 150.79400635  30.60079956]\n",
      " [ 70.23670197 142.76100159  27.95319939]\n",
      " [ 69.87650299 133.66600037  25.61359978]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[num,:,:])\n",
    "print(y_train[num,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step\n",
      "[[[ 73.87105  205.78673   40.53266 ]\n",
      "  [ 73.234406 196.15947   39.186577]\n",
      "  [ 72.87796  186.53268   37.904804]\n",
      "  [ 72.61771  177.02203   36.43546 ]\n",
      "  [ 72.28131  167.63637   34.674564]\n",
      "  [ 71.902374 158.38791   32.717594]\n",
      "  [ 71.50011  149.2056    30.597805]\n",
      "  [ 71.10336  140.1226    28.31211 ]\n",
      "  [ 70.746956 131.29944   25.866669]]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_train[num,:,:].reshape(1,9,3), verbose=1)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.24205017,  1.04226685, -0.09955978],\n",
       "        [-0.08870697,  0.42953491,  0.49702454],\n",
       "        [-0.19656372,  0.29431152,  0.44609451],\n",
       "        [-0.58200836,  2.12496948, -0.12345886],\n",
       "        [-0.47531128,  0.06663513,  0.39903641],\n",
       "        [-0.70097351,  1.4520874 ,  0.27850723],\n",
       "        [-0.69500732,  1.58840942,  0.00299454],\n",
       "        [-0.86666107,  2.63839722, -0.35891151],\n",
       "        [-0.87045288,  2.36656189, -0.25306892]]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = y_train[num,:,:].reshape(1,9,3)-y_pred\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
